{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Data:\n",
      "    UserID Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455\n",
      "Movies Data:\n",
      "    MovieID                               Title                        Genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "Ratings Data:\n",
      "    UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n"
     ]
    }
   ],
   "source": [
    "#importing and Preprocessing the data \n",
    "#We need to clean and prepare the data for both MF and NCF models\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, accuracy_score\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Load the datasets\n",
    "users = pd.read_csv(r'D:\\unitec\\MachineLearningCourse\\movie_Recommedation\\ml-1m\\users.dat', \n",
    "                    sep='::', engine='python', \n",
    "                    names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], \n",
    "                    encoding='ISO-8859-1')\n",
    "\n",
    "movies = pd.read_csv(r'D:\\unitec\\MachineLearningCourse\\movie_Recommedation\\ml-1m\\movies.dat', \n",
    "                     sep='::', engine='python', \n",
    "                     names=['MovieID', 'Title', 'Genres'], \n",
    "                     encoding='ISO-8859-1')\n",
    "\n",
    "ratings = pd.read_csv(r'D:\\unitec\\MachineLearningCourse\\movie_Recommedation\\ml-1m\\ratings.dat', \n",
    "                      sep='::', engine='python', \n",
    "                      names=['UserID', 'MovieID', 'Rating', 'Timestamp'], \n",
    "                      encoding='ISO-8859-1')\n",
    "\n",
    "# Check the loaded data\n",
    "print(\"Users Data:\\n\", users.head())\n",
    "print(\"Movies Data:\\n\", movies.head())\n",
    "print(\"Ratings Data:\\n\", ratings.head())\n",
    "\n",
    "# Create a pivot table for Matrix Factorization (MF) model\n",
    "ratings_pivot = ratings.pivot_table(index='UserID', columns='MovieID', values='Rating')\n",
    "\n",
    "# Fill missing values with 0 (could be done with other techniques too, but here we use 0 for simplicity)\n",
    "ratings_pivot = ratings_pivot.fillna(0)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF Model MSE:  4.98856493164911\n",
      "MF Model R²:  -2.9787799185725476\n",
      "Confusion Matrix:\n",
      " [[82168  2712]\n",
      " [94680 20482]]\n",
      "Accuracy:  0.5131422401295728\n"
     ]
    }
   ],
   "source": [
    "#Matrix Factorization (MF) - SVD\n",
    "#Singular Value Decomposition (SVD). This is a traditional matrix factorization method for recommendation systems.\n",
    "\n",
    "# Perform SVD on the ratings matrix \n",
    "\n",
    "# Create user and movie ID mappings to indices\n",
    "user_mapping = {user_id: index for index, user_id in enumerate(ratings_pivot.index)}\n",
    "movie_mapping = {movie_id: index for index, movie_id in enumerate(ratings_pivot.columns)}\n",
    "\n",
    "# Updated prediction function using the mappings\n",
    "def predict_rating(user_id, movie_id):\n",
    "    user_index = user_mapping.get(user_id)  # Map user_id to index\n",
    "    movie_index = movie_mapping.get(movie_id)  # Map movie_id to index\n",
    "    if user_index is not None and movie_index is not None:\n",
    "        return predicted_ratings[user_index, movie_index]  # Access the predicted rating\n",
    "    else:\n",
    "        return 0  # Return a default value if user or movie is not in the matrix\n",
    "\n",
    "# Evaluate the model\n",
    "y_true = test_data['Rating']\n",
    "y_pred = [predict_rating(row['UserID'], row['MovieID']) for index, row in test_data.iterrows()]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(\"MF Model MSE: \", mse)\n",
    "print(\"MF Model R²: \", r2)\n",
    "\n",
    "# Calculate confusion matrix and accuracy (using a simple threshold for binary classification)\n",
    "threshold = 3.5\n",
    "y_pred_binary = [1 if pred >= threshold else 0 for pred in y_pred]\n",
    "y_true_binary = [1 if rating >= threshold else 0 for rating in y_true]\n",
    "\n",
    "cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
    "accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  MovieID  user_idx  movie_idx\n",
      "0       1     1193         0          0\n",
      "1       1      661         0          1\n",
      "2       1      914         0          2\n",
      "3       1     3408         0          3\n",
      "4       1     2355         0          4\n"
     ]
    }
   ],
   "source": [
    "#Before using the UserID and MovieID in the model, we need to map them to zero-based indices.\n",
    "# Map original UserID and MovieID to zero-indexed values\n",
    "user_map = {user_id: idx for idx, user_id in enumerate(ratings['UserID'].unique())}\n",
    "movie_map = {movie_id: idx for idx, movie_id in enumerate(ratings['MovieID'].unique())}\n",
    "\n",
    "# Re-index the user and movie columns in the ratings data\n",
    "ratings['user_idx'] = ratings['UserID'].map(user_map)\n",
    "ratings['movie_idx'] = ratings['MovieID'].map(movie_map)\n",
    "\n",
    "# Check the changes\n",
    "print(ratings[['UserID', 'MovieID', 'user_idx', 'movie_idx']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800167, 2) (200042, 2) (800167,) (200042,)\n"
     ]
    }
   ],
   "source": [
    "# Now, we need to update the training and testing datasets to use the new user_idx and movie_idx.\n",
    "# Split data into train and test sets (80% train, 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = ratings[['user_idx', 'movie_idx']].values\n",
    "y = ratings['Rating'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, including user and movie embeddings\n",
    "# Number of unique users and movies after re-indexing\n",
    "n_users = len(user_map)\n",
    "n_movies = len(movie_map)\n",
    "\n",
    "\n",
    "user_input = Input(shape=(1,), name='user_input')\n",
    "movie_input = Input(shape=(1,), name='movie_input')\n",
    "\n",
    "user_embedding = Embedding(input_dim=n_users, output_dim=n_factors, name='user_embedding')(user_input)\n",
    "movie_embedding = Embedding(input_dim=n_movies, output_dim=n_factors, name='movie_embedding')(movie_input)\n",
    "\n",
    "user_flat = Flatten()(user_embedding)\n",
    "movie_flat = Flatten()(movie_embedding)\n",
    "\n",
    "concat = Concatenate()([user_flat, movie_flat])\n",
    "\n",
    "dense = Dense(128, activation='relu')(concat)\n",
    "dense = Dense(64, activation='relu')(dense)\n",
    "dense = Dense(32, activation='relu')(dense)\n",
    "output = Dense(1)(dense)\n",
    "\n",
    "model = Model(inputs=[user_input, movie_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 9ms/step - accuracy: 0.0563 - loss: 0.6399 - val_accuracy: 0.0570 - val_loss: 0.7682\n",
      "Epoch 2/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 9ms/step - accuracy: 0.0560 - loss: 0.6006 - val_accuracy: 0.0570 - val_loss: 0.7767\n",
      "Epoch 3/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 9ms/step - accuracy: 0.0560 - loss: 0.5676 - val_accuracy: 0.0570 - val_loss: 0.7866\n",
      "Epoch 4/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 8ms/step - accuracy: 0.0561 - loss: 0.5373 - val_accuracy: 0.0570 - val_loss: 0.7956\n",
      "Epoch 5/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 8ms/step - accuracy: 0.0559 - loss: 0.5093 - val_accuracy: 0.0570 - val_loss: 0.8103\n",
      "Epoch 6/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 9ms/step - accuracy: 0.0556 - loss: 0.4834 - val_accuracy: 0.0570 - val_loss: 0.8250\n",
      "Epoch 7/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 9ms/step - accuracy: 0.0561 - loss: 0.4597 - val_accuracy: 0.0570 - val_loss: 0.8326\n",
      "Epoch 8/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 10ms/step - accuracy: 0.0563 - loss: 0.4385 - val_accuracy: 0.0570 - val_loss: 0.8555\n",
      "Epoch 9/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 9ms/step - accuracy: 0.0561 - loss: 0.4171 - val_accuracy: 0.0570 - val_loss: 0.8694\n",
      "Epoch 10/10\n",
      "\u001b[1m12503/12503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 9ms/step - accuracy: 0.0560 - loss: 0.4010 - val_accuracy: 0.0570 - val_loss: 0.8832\n"
     ]
    }
   ],
   "source": [
    "#Train the model, using the user_idx and movie_idx and the updated ratings.\n",
    "history = model.fit([X_train[:, 0], X_train[:, 1]], y_train, epochs=10, batch_size=64, validation_data=([X_test[:, 0], X_test[:, 1]], y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6252/6252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n",
      "MSE: 0.8832063651378971\n",
      "R²: 0.29557228088378906\n",
      "Confusion Matrix:\n",
      " [[55809 29071]\n",
      " [26881 88281]]\n",
      "Accuracy: 0.7202987372651743\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings for the test set\n",
    "y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "\n",
    "# Evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Convert ratings to binary values (e.g., ratings >= 3.5 are positive)\n",
    "threshold = 3.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "y_test_binary = (y_test >= threshold).astype(int)\n",
    "\n",
    "# Confusion matrix and accuracy\n",
    "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[661 495 878 994 836]\n"
     ]
    }
   ],
   "source": [
    "print(type(movies))  # Should output <class 'pandas.core.frame.DataFrame'>\n",
    "print(top_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 71/116\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi thakur\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['user_input', 'movie_input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Recommended Movies:\n",
      "                          Title          Genres\n",
      "1414  Meet Wally Sparks (1997)          Comedy\n",
      "1777       Nil By Mouth (1997)           Drama\n",
      "1567                187 (1997)           Drama\n",
      "2350        Extremities (1986)  Drama|Thriller\n",
      "2442  Long Goodbye, The (1973)           Crime\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings for a specific user\n",
    "user_id = 0\n",
    "movie_ids = np.array(list(range(n_movies)))\n",
    "\n",
    "predictions = model.predict([np.full(movie_ids.shape, user_id), movie_ids])\n",
    "\n",
    "# Recommend top 5 movies\n",
    "top_movie_ids = predictions.flatten().argsort()[::-1][:5]\n",
    "recommended_movies = movies.iloc[top_movie_ids]\n",
    "\n",
    "print(\"Recommended Movies:\\n\", recommended_movies[['Title', 'Genres']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Rating for User 0 and Movie 100: 0.029850271996437007\n"
     ]
    }
   ],
   "source": [
    "# Let's predict a rating for user with id 0 for movie with id 100\n",
    "user_id = 0\n",
    "movie_id = 100\n",
    "\n",
    "# Predict the rating by calculating the dot product of user and movie latent factors\n",
    "predicted_rating = np.dot(user_factors[user_id, :], movie_factors[movie_id, :])\n",
    "\n",
    "print(f\"Predicted Rating for User {user_id} and Movie {movie_id}: {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Recommended Movies for User 0:\n",
      "                               Title                       Genres\n",
      "0                  Toy Story (1995)  Animation|Children's|Comedy\n",
      "2898           Bad Seed, The (1956)               Drama|Thriller\n",
      "581   Brady Bunch Movie, The (1995)                       Comedy\n",
      "513               Rising Sun (1993)         Action|Drama|Mystery\n",
      "2162                Rounders (1998)                  Crime|Drama\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings for all movies for a specific user\n",
    "user_id = 0\n",
    "predicted_ratings = np.dot(user_factors[user_id, :], movie_factors.T)\n",
    "\n",
    "# Get top 5 movie recommendations\n",
    "top_movie_ids = predicted_ratings.argsort()[::-1][:5]\n",
    "\n",
    "# Retrieve the titles of the top recommended movies\n",
    "recommended_movies = movies.iloc[top_movie_ids]\n",
    "\n",
    "print(\"Top 5 Recommended Movies for User 0:\\n\", recommended_movies[['Title', 'Genres']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Top 5 Recommended Movies for User 0:\n",
      "                                               Title  \\\n",
      "346                              Client, The (1994)   \n",
      "106                                  Catwalk (1995)   \n",
      "309                  Stuart Saves His Family (1995)   \n",
      "1108                          On Golden Pond (1981)   \n",
      "2931  Princess Mononoke, The (Mononoke Hime) (1997)   \n",
      "\n",
      "                          Genres  \n",
      "346       Drama|Mystery|Thriller  \n",
      "106                  Documentary  \n",
      "309                       Comedy  \n",
      "1108                       Drama  \n",
      "2931  Action|Adventure|Animation  \n"
     ]
    }
   ],
   "source": [
    "# Predict ratings for all movies for a specific user\n",
    "user_id = 0\n",
    "movie_ids = np.array(list(range(n_movies)))  # all movie IDs\n",
    "\n",
    "# Predict ratings for each movie\n",
    "predictions = model.predict([np.full(movie_ids.shape, user_id), movie_ids])\n",
    "\n",
    "# Get top 5 movie recommendations\n",
    "top_movie_ids = predictions.flatten().argsort()[::-1][:5]\n",
    "\n",
    "# Retrieve the titles of the top recommended movies\n",
    "recommended_movies = movies.iloc[top_movie_ids]\n",
    "\n",
    "print(\"Top 5 Recommended Movies for User 0:\\n\", recommended_movies[['Title', 'Genres']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Title                              Genres\n",
      "593               Pretty Woman (1990)                      Comedy|Romance\n",
      "2557         Edge of Seventeen (1998)                Comedy|Drama|Romance\n",
      "2651          Inspector Gadget (1999)  Action|Adventure|Children's|Comedy\n",
      "1107      Perfect Candidate, A (1996)                         Documentary\n",
      "579   Dear Diary (Caro Diario) (1994)                        Comedy|Drama\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies_svd(user_id, num_recommendations=5):\n",
    "    # Predict ratings for all movies for the user\n",
    "    predicted_ratings = np.dot(user_factors[user_id, :], movie_factors.T)\n",
    "    \n",
    "    # Get the top movie recommendations\n",
    "    top_movie_ids = predicted_ratings.argsort()[::-1][:num_recommendations]\n",
    "    \n",
    "    # Retrieve the recommended movie titles\n",
    "    recommended_movies = movies.iloc[top_movie_ids]\n",
    "    return recommended_movies[['Title', 'Genres']]\n",
    "\n",
    "# Example: Recommend top 5 movies for User 10\n",
    "recommended = recommend_movies_svd(user_id=10)\n",
    "print(recommended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "                                                Title       Genres\n",
      "2158                               Lodger, The (1926)     Thriller\n",
      "713   Haunted World of Edward D. Wood Jr., The (1995)  Documentary\n",
      "3021                                   Matewan (1987)        Drama\n",
      "2809                                Hell Night (1981)       Horror\n",
      "862      Shadow of Angels (Schatten der Engel) (1976)        Drama\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies_ncf(user_id, num_recommendations=5):\n",
    "    # Predict ratings for all movies for the user\n",
    "    movie_ids = np.array(list(range(n_movies)))\n",
    "    predictions = model.predict([np.full(movie_ids.shape, user_id), movie_ids])\n",
    "    \n",
    "    # Get the top movie recommendations\n",
    "    top_movie_ids = predictions.flatten().argsort()[::-1][:num_recommendations]\n",
    "    \n",
    "    # Retrieve the recommended movie titles\n",
    "    recommended_movies = movies.iloc[top_movie_ids]\n",
    "    return recommended_movies[['Title', 'Genres']]\n",
    "\n",
    "recommended = recommend_movies_ncf(user_id=4)\n",
    "print(recommended)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
